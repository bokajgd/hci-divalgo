{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIVALGO demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains a demostration of the DIVALGO tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import importlib\n",
    "import divalgo.divalgo_class\n",
    "importlib.reload(divalgo.divalgo_class)\n",
    "import divalgo.divalgo_class as div\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual data - dogs and wolfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "dogs = sorted(os.listdir(os.path.join(\"data\", \"dogs\")))\n",
    "wolves =  sorted(os.listdir(os.path.join(\"data\", \"wolves\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "img_size = 50\n",
    "dogs_images = []\n",
    "wolves_images = [] \n",
    "\n",
    "for i in dogs:\n",
    "    if os.path.isfile(os.path.join(\"data\", \"dogs\", f\"{i}\")):\n",
    "        img = Image.open(os.path.join(\"data\", \"dogs\", f\"{i}\")).convert('L')            \n",
    "        img = img.resize((img_size,img_size), Image.ANTIALIAS)\n",
    "        img = np.asarray(img)/255.0\n",
    "        dogs_images.append(img)    \n",
    "\n",
    "for i in wolves:\n",
    "    if os.path.isfile(os.path.join(\"data\", \"data\", \"wolves\", f\"{i}\")):\n",
    "        img = Image.open(os.path.join(\"data\", \"data\", \"wolves\", f\"{i}\")).convert('L')\n",
    "        img = img.resize((img_size,img_size), Image.ANTIALIAS)\n",
    "        img = np.asarray(img)/255.0     \n",
    "        wolves_images.append(img)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual train-test split (to track filenames)\n",
    "X_train = np.asarray(dogs_images[0:800] + wolves_images[0:800])\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2])\n",
    "X_test = np.asarray(dogs_images[800:1000] + wolves_images[800:1000])\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2])\n",
    "y_train = np.asarray([\"dog\" for y in range(800)] + [\"wolf\" for y in range(800)])\n",
    "y_train = y_train.reshape(y_train.shape[0],1)\n",
    "y_test_ar = np.asarray([\"dog\" for y in range(200)] + [\"wolf\" for y in range(200)])\n",
    "y_test = y_test_ar.reshape(y_test_ar.shape[0],1)\n",
    "\n",
    "y_train, y_test = [k.T for k in [y_train, y_test]]\n",
    "filenames_test = [os.path.join(\"data\", \"dogs\", d) for d in dogs[800:1000]] + [os.path.join(\"data\", \"wolves\", w) for w in wolves[800:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model = LogisticRegression(penalty='none', tol=0.1).fit(X_train, y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "dog_wolf = div.Evaluate((X_test, y_test[0], y_pred, filenames_test), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  You can now view your Streamlit app in your browser.\n",
      "\n",
      "  Local URL: http://localhost:8501\n",
      "  Network URL: http://192.168.8.148:8501\n",
      "\n",
      "  Stopping...\n"
     ]
    }
   ],
   "source": [
    "dog_wolf.open_visualization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training: \n",
    "\n",
    "Train - epoch - loss over time, learning curves (Frida)\n",
    "\n",
    "Coefficient heatmap (Jakob)\n",
    "\n",
    "Visualize images (correct/wrong predictions) - Stine "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8bbca557228c58e4cbc263502a3dcefff61a59306cd42f33a4b53cb99199cce0"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('hcienv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
